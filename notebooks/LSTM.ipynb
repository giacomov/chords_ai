{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning music with a RNN - episode 2: the model\n",
    "\n",
    "In episode 1 we have gathered a set of around 5000 songs from the best 100 rock artists according to Rolling Stones. We now will train a Recurrent Neural Network on the sample and use it (in the next episode) to generate new sequences of chords.\n",
    "\n",
    "## Read the dataset\n",
    "\n",
    "Let's load the dataset we have generated in Episode 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import a bunch of things we will use\n",
    "\n",
    "import os\n",
    "os.environ['MKL_NUM_THREADS'] = '8'\n",
    "os.environ['OMP_NUM_THREADS'] = '8'\n",
    "\n",
    "# Force TensorFlow to run on the CPU (the GPU of my laptop is too slow for these things)\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, BatchNormalization, Activation\n",
    "from keras import optimizers\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now read in the chord sequences for all the songs we have selected in Episode 1, as well as the vocabulary (i.e., the chords used in these songs):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of songs: 5678\n",
      "Size of vocabulary: 65\n"
     ]
    }
   ],
   "source": [
    "# Read sequences and vocabulary\n",
    "# NOTE: the two JSON files used here are produced during Episode 1,\n",
    "# you need to run that first\n",
    "songs = pd.read_json(\"best_songs_cleaned.json\", typ='series')\n",
    "\n",
    "print(\"Number of songs: %s\" % len(songs))\n",
    "\n",
    "with open(\"best_songs_vocabulary.json\") as f:\n",
    "    \n",
    "    vocabulary = json.load(f)\n",
    "\n",
    "# Sort alphabetically\n",
    "vocabulary = sorted(vocabulary)\n",
    "\n",
    "print(\"Size of vocabulary: %i\" % len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also take a peek of what the data actually look like by printing the first few rows of our data frame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Examples of chord sequences:\n",
      "0                                                 E A E A\n",
      "1       E D A E D A G# Bb A B Bb C B E A E B A B A E B...\n",
      "100     E C# A F# B E C# A F# B E C# A F# B E C# A F# ...\n",
      "1000    E A G#m C#m7 B E A E G#m E A E G#m E G#m E G#m...\n",
      "1001                        F Dm G F Dm G F Dm G F Dm G F\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"Examples of chord sequences:\")\n",
    "print(songs.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model we will use does not understand chords per se. Instead, we assign a integer to each chord using a mapping between the vocabulary and the integers.\n",
    "\n",
    "The network will then predict an integer instead of a chord. We will then reverse the mapping to obtain our predicted chord:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping = {k:v for k,v in zip(vocabulary, range(len(vocabulary)))}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A character-level language model\n",
    "\n",
    "In order to achieve our goal we are going to train a character-level language model, where each \"character\" corresponds to a chord. In other words, our model will predict the next chord given a sequence of previous chords.\n",
    "\n",
    "So for example, let's consider the following sequence: \"C Am Dm G7 C C7 F C\". We will ask the network to predict the last \"C\" given the input sequence \"C Am Dm G7 C C7 F\". \n",
    "\n",
    "The length of the input sequence must be decided a priori. Using a short sequence will not give a lot of context to the network, which will then won't have much information. On the contrary, using a sequence too long will make the training difficult as the network will need more and more long term memory and the number of possible sequences will explode combinatorially. I found a good trade off using a input legnth of 8.\n",
    "\n",
    "In order to train the network we then need to divide our songs in input sequences `X` and expected outputs `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sequences: 256242\n",
      "Songs skipped: 265\n"
     ]
    }
   ],
   "source": [
    "# Now we need to generate sequences for each song\n",
    "\n",
    "# Length of the input sequence\n",
    "seq_length = 8\n",
    "\n",
    "sequences = []\n",
    "skipped = 0\n",
    "\n",
    "# Loop over the songs and accumulate sequences\n",
    "for i, song in enumerate(songs):\n",
    "        \n",
    "    # Split the song in chords, then assign the corresponding integer from\n",
    "    # the mapping\n",
    "    these_chords = map(lambda x:mapping[x], song.split())\n",
    "    \n",
    "    # Make sure there are no repetitions of the same chord (see Episode 1)\n",
    "    assert np.all(np.diff(these_chords)!=0)\n",
    "    \n",
    "    # A song needs to be seq_length + 1 long to be useful for our purposes,\n",
    "    # because we need an input sequence of length \"seq_length\" and an expected\n",
    "    # output (the other chord, i.e., the \"+1\"). If the song is shorter then\n",
    "    # seq_length + 1 we cannot use it\n",
    "    if len(these_chords) < seq_length + 1:\n",
    "\n",
    "        # Skip this song\n",
    "        skipped += 1\n",
    "        continue\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Let's accumulate all sequences contained in the song, \n",
    "        # without wrapping around the edge\n",
    "        for i in range(len(these_chords) - (seq_length + 1) + 1):\n",
    "            \n",
    "            sequences.append(these_chords[i:i+seq_length+1])\n",
    "\n",
    "# Make sure all sequences are of the proper length\n",
    "l = map(lambda x:len(x), sequences)\n",
    "assert np.all(np.array(l)==seq_length+1)\n",
    "\n",
    "print(\"Number of sequences: %s\" % len(sequences))\n",
    "print(\"Songs skipped: %s\" % skipped)\n",
    "\n",
    "# Number of sequences: 257570\n",
    "# Songs skipped: 265"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now split our sequences in inputs (`X`) and output (`y`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)\n",
    "X, y = sequences[:,:-1], sequences[:,-1]\n",
    "\n",
    "np.savez(\"sequences.npz\", X=X, y=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the LSTM model\n",
    "\n",
    "For this project I will use the LSTM implementation of (Keras)[https://keras.io/]). \n",
    "\n",
    "Our RNN is made of 3 layers:\n",
    "\n",
    "1. Embedding layer: this layer maps each chord (represented as an integer) to a point in a dense n-dimensional space (called the \"embedding\" of the input). For example, let's say that \"C\" is represented by the integer 1. After the embedding layer, \"C\" will be instead represented by say the vector [0.5, 0.2, 0.3, 0.6]. Why doing this? Because during the training a mapping will be learned so that items with a similar function will be nearby in this space. For example, let's consider the chord of \"C\" major. Its (minor relative)[http://www.musiceducatorsinstitute.com/course/guitar/course3/M02S01_relative_chords.html] \"Am\" is going to be close by in the n-dimensional space because in many context they can be used together. We also expect to find close by the chords of the key of C major. Instead, chords of other keys should be further away. This helps the network learn the function of each chord in its context.\n",
    "2. Long Short Term Memory layer: this is a standard LSTM layer. We use a little bit of [dropout](https://medium.com/@amarbudhiraja/https-medium-com-amarbudhiraja-learning-less-to-learn-better-dropout-in-deep-machine-learning-74334da4bfc5) regularization to avoid overfitting.\n",
    "3. Dense layer: a normal fully-connected layer with a [softmax](https://en.wikipedia.org/wiki/Softmax_function) activation function. In order to make the training a little faster, we use (Batch Normalization)[https://towardsdatascience.com/batch-normalization-in-neural-networks-1ac91516821c] here. Thanks to this dense layer the output of the RNN will be the probability for each of the chords in the vocabulary to be the next chord, given the input sequence.  We will use this information to make the behavior of our predictions a little more vary than just predicting always the same output for the same input (see Episode 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 8, 3)              195       \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 300)               364800    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 65)                19565     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 65)                260       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 65)                0         \n",
      "=================================================================\n",
      "Total params: 384,820\n",
      "Trainable params: 384,690\n",
      "Non-trainable params: 130\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# We do not one-hot-encode because we will use the \n",
    "# sparse_categorical_crossentropy as loss function\n",
    "model = Sequential()\n",
    "model.add(Embedding(len(vocabulary), \n",
    "                    3, \n",
    "                    input_length=seq_length,\n",
    "                    name='embedding'))\n",
    "model.add(LSTM(300, recurrent_dropout=0.0,\n",
    "               name='lstm', \n",
    "               return_sequences=False))\n",
    "model.add(Dense(len(vocabulary), name='dense'))\n",
    "model.add(BatchNormalization(name='batch_normalization'))\n",
    "model.add(Activation('softmax', name='activation'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the progress of the model we introduce a custom metric, based on the `sparse_top_k_categorical_accuracy` implemented in Keras. Remember that the output of our network will be the probability for each of the chords in the dictionary of being the next chord, given an input sequence. The metric considers an outcome a success if one of the first `k` most probable values predicted by the network is the true value. In the normal accuracy measurement, instead, the outcome is considered a success only if the most probable value according to the network is the truth. We choose this metric because it helps to account for the fact that, given a sequence of chords, there is more than one \"correct\" possibility for the next one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define metric and compile model\n",
    "from chords_ai.custom_metric import sparse_top_k_categorical_accuracy_3\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "              optimizer=\"adam\", metrics=['acc', sparse_top_k_categorical_accuracy_3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the network\n",
    "\n",
    "Now we can train the network. But first we need to set aside a test set, so that we can evaluate the performances of the network on it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split test dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "    \n",
    "# Let's set aside 20% of the sequences, chosen randomly\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                                    shuffle=True)\n",
    "\n",
    "def get_class_weights(y):\n",
    "    \n",
    "    counter = Counter(y)\n",
    "    majority = max(counter.values())\n",
    "    unnorm_w = {cls: float(majority)/count for cls, count in counter.items()}\n",
    "    \n",
    "    tot = float(np.sum(unnorm_w.values()))\n",
    "    \n",
    "    normed_weights = {k: v / 1.0 for k, v in unnorm_w.items()}\n",
    "    \n",
    "    return normed_weights\n",
    "\n",
    "class_weights = get_class_weights(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run the fit then:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 204993 samples, validate on 51249 samples\n",
      "Epoch 1/10\n",
      "204993/204993 [==============================] - 94s 459us/step - loss: 30.9977 - acc: 0.1121 - sparse_top_k_categorical_accuracy_3: 0.2875 - val_loss: 3.7188 - val_acc: 0.0360 - val_sparse_top_k_categorical_accuracy_3: 0.1106\n",
      "Epoch 2/10\n",
      "204993/204993 [==============================] - 94s 460us/step - loss: 27.9009 - acc: 0.1711 - sparse_top_k_categorical_accuracy_3: 0.4149 - val_loss: 4.1902 - val_acc: 0.0323 - val_sparse_top_k_categorical_accuracy_3: 0.0828\n",
      "Epoch 3/10\n",
      "204993/204993 [==============================] - 94s 459us/step - loss: 26.3861 - acc: 0.1792 - sparse_top_k_categorical_accuracy_3: 0.4321 - val_loss: 3.3960 - val_acc: 0.1319 - val_sparse_top_k_categorical_accuracy_3: 0.3288\n",
      "Epoch 4/10\n",
      "204993/204993 [==============================] - 95s 466us/step - loss: 25.2615 - acc: 0.1823 - sparse_top_k_categorical_accuracy_3: 0.4390 - val_loss: 3.1654 - val_acc: 0.1740 - val_sparse_top_k_categorical_accuracy_3: 0.4074\n",
      "Epoch 5/10\n",
      "204993/204993 [==============================] - 96s 468us/step - loss: 24.0278 - acc: 0.2001 - sparse_top_k_categorical_accuracy_3: 0.4648 - val_loss: 3.0834 - val_acc: 0.2191 - val_sparse_top_k_categorical_accuracy_3: 0.4808\n",
      "Epoch 6/10\n",
      "204993/204993 [==============================] - 98s 478us/step - loss: 22.8755 - acc: 0.2120 - sparse_top_k_categorical_accuracy_3: 0.4847 - val_loss: 3.1259 - val_acc: 0.2097 - val_sparse_top_k_categorical_accuracy_3: 0.4730\n",
      "Epoch 7/10\n",
      "204993/204993 [==============================] - 102s 498us/step - loss: 21.8162 - acc: 0.2209 - sparse_top_k_categorical_accuracy_3: 0.4984 - val_loss: 3.0931 - val_acc: 0.2052 - val_sparse_top_k_categorical_accuracy_3: 0.4513\n",
      "Epoch 8/10\n",
      "204993/204993 [==============================] - 95s 463us/step - loss: 20.9860 - acc: 0.2278 - sparse_top_k_categorical_accuracy_3: 0.5096 - val_loss: 2.8709 - val_acc: 0.2345 - val_sparse_top_k_categorical_accuracy_3: 0.5277\n",
      "Epoch 9/10\n",
      "204993/204993 [==============================] - 100s 488us/step - loss: 20.0608 - acc: 0.2367 - sparse_top_k_categorical_accuracy_3: 0.5233 - val_loss: 2.9602 - val_acc: 0.2258 - val_sparse_top_k_categorical_accuracy_3: 0.5004\n",
      "Epoch 10/10\n",
      "204993/204993 [==============================] - 92s 450us/step - loss: 19.2122 - acc: 0.2465 - sparse_top_k_categorical_accuracy_3: 0.5384 - val_loss: 2.8928 - val_acc: 0.2493 - val_sparse_top_k_categorical_accuracy_3: 0.5263\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f08fc2263d0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To avoid overtraining (aka memorization), we use early \n",
    "# stopping, i.e., keras stops the training when the accuracy \n",
    "# on the validation dataset stops improving.\n",
    "# We use patience=10, which means that keras will stop the\n",
    "# training after 10 epochs where the metrics did not improve.\n",
    "# This is needed because due to the random nature of the training\n",
    "# the metric could not improve for a few epochs and then jump\n",
    "# up, we do not want to stop too early.\n",
    "\n",
    "n_epochs = 10 # We'll never reach 1000 epochs because \n",
    "                # of early stopping\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_sparse_top_k_categorical_accuracy_3', \n",
    "                               patience=20, \n",
    "                               verbose=0)\n",
    "\n",
    "# We use checkpointing, i.e., we keep track of the iteration with \n",
    "# the best accuracy and save it to a file.  Since there is some \n",
    "# randomness involved in the training, the val_acc could be at \n",
    "# its maximum not in the very last epoch.\n",
    "\n",
    "check_point = ModelCheckpoint(\"best_weights.h5\", \n",
    "                              monitor='val_acc', \n",
    "                              verbose=0, \n",
    "                              save_best_only=True, \n",
    "                              save_weights_only=True, \n",
    "                              mode='min')\n",
    "\n",
    "callbacks = [early_stopping, check_point]\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=256, verbose=1, shuffle=True,\n",
    "          initial_epoch=0, epochs=n_epochs,\n",
    "          validation_data=(X_test, y_test),\n",
    "          callbacks=callbacks,\n",
    "         class_weight=class_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no point in continuing the training (actually we could have stopped earler). We can now save the model, which will then use in Episode 3 to generate new chord sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(\"best_weights.h5\")\n",
    "\n",
    "model.save(\"model_best_songs.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
